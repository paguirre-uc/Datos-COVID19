{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "IMT2200_clase3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYgKbz8V5ufT"
      },
      "source": [
        "# <img style=\"float: left; padding-right: 20px; width: 100px\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Escudo_de_la_Pontificia_Universidad_Cat%C3%B3lica_de_Chile.svg/1920px-Escudo_de_la_Pontificia_Universidad_Cat%C3%B3lica_de_Chile.svg.png\"> IMT 2200 - Introducción a Ciencia de Datos\n",
        "**Pontificia Universidad Católica de Chile**<br>\n",
        "**Semestre 2021-1**<br>\n",
        "**Profesora:** Paula Aguirre <br>\n",
        "\n",
        "## Clase 3: Tipos y formatos de datos\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skvKPmCV5ufV"
      },
      "source": [
        "Data Product 3 - Casos totales por región incremental: Archivo con valores separados por coma (csv) que concatena historia de publicaciones de casos totales por parte de MINSAL. El archivo contiene una columna 'Región', seguida por columnas correspondientes a '[fecha]'. Estas últimas columnas, ‘[fecha]’, contienen los 'Casos Confirmados' reportados por el Ministerio de Salud de Chile en cada una de las fechas que se indican en las respectivas columnas. Incluye versión con serie de tiempo. Ver más.\n",
        "\n",
        "\n",
        "## 1. Módulos de Python\n",
        "\n",
        "Todos los Notebooks y códigos deberían comenzar con la importación de módulos, o librerías de funciones built-in para distintos usos. Para facilitar la referencia a librerías en el resto del código, se acostumbra asignarles un alias. La sintaxis a usar para importar un módulo es:\n",
        "\n",
        "\n",
        "``import NOMBRE_MODULO as ALIAS_MODULO``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_-vYdVK5ufW",
        "outputId": "0f2ed944-692b-4927-f5d6-3a80d50e7b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install geopandas\n",
        "import geopandas as gpd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "  Downloading geopandas-0.9.0-py2.py3-none-any.whl (994 kB)\n",
            "\u001b[K     |████████████████████████████████| 994 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Collecting fiona>=1.8\n",
            "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 37 kB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "  Downloading pyproj-3.1.0-cp37-cp37m-manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 46.2 MB/s \n",
            "\u001b[?25hCollecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.2.0)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.5.30)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2.8.2)\n",
            "Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.9.0 munch-2.5.0 pyproj-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMGyFNNk5ufX"
      },
      "source": [
        "## 2. Ubicación de archivos.\n",
        "\n",
        "Antes de improtar archvios de datos, necesitamos identificar dónde están guardados dentro de nuestro sistema, y en qué directorio estamos trabajando (\"working directory\").\n",
        "\n",
        "Algunos comandos importantes:\n",
        "- `!ls`: lista el contenido del directorio actual command lists all content in the current working directory.\n",
        "- `%cd 'subdirectorio'`: permite cambiar la ubicación actual a 'subdirectorio'\n",
        "- `cd ..`: permite navegar hacia atrás al directorio superior del actual\n",
        "- `!pwd`: entrega la ruta del directorio actual\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B02q57_55ufX"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUlZ-itQ5ufY"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO14YGKy5ufY"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKbzYX1U5ufZ"
      },
      "source": [
        "!ls\n",
        "%cd clase3\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMOFhstL5ufa"
      },
      "source": [
        "data_file='CasosTotalesCumulativo.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOoV72Z95ufa"
      },
      "source": [
        "## 2. Importación de datos.\n",
        "\n",
        "Veremos primero cómo importar, inspeccionar y graficar datos estructurados.\n",
        "\n",
        "### 2.1 `numpy`: np.loadtxt() y np.genfromtxt()\n",
        "\n",
        "Numpy provee funciones para leer archivos de texto estructurado directamente como arreglos (`np.ndarray`). En primer lugar la función `np.loadtxt()`, permite cargar archivos cuyo contenido es solamente numérico. Sin embargo, generalmente trabajaremos con datasets que tienen distintos tipos de datos en distintas columnas; por ejemplo, strings y floats. En este caso, es necesario utilizar la función `np.genfromtxt()`, que puede manejar estas estructuras. Si pasamos como argumento `dtype=None`, la función infiere el tipo de datos de cada columna.\n",
        "\n",
        "La documentación de ambas funciones se encuentra en: <br>\n",
        "- https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html\n",
        "- https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3IIpGZ95ufa"
      },
      "source": [
        "# Importar archivo: data\n",
        "data = np.loadtxt(data_file, delimiter=',', dtype='str')#skiprows=1\n",
        "\n",
        "# Explorar la data\n",
        "print(data[0])\n",
        "print(data.shape)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o36L2fmd5ufb"
      },
      "source": [
        "# Importar data como floats y saltar la primera fila: data_float\n",
        "data = np.genfromtxt(data_file, delimiter=',', dtype=None,skip_header=1)\n",
        "\n",
        "print(data[0])\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "#numpy se las puede arreglar con datos mezclados pero es mejor panda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plZWesG05ufb"
      },
      "source": [
        "En general, `numpy` se las puede arreglar con conjuntos de datos con tipos mezclados, pero la librería natural para trabajar con datos estructurados es `pandas`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_QQVZLX5ufb"
      },
      "source": [
        "### 2.2 `pandas`: read_csv y DataFrames\n",
        "\n",
        "La función `pd.read_csv()` permite leer un archivo de texto en formato CSV (comma separated value) y generar un DataFrame.\n",
        "El delimitador por defecto es la coma (,), pero también pueden leerse datasets con otros tipos de separación, especificando el parámetro `delimiter`.\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
        "\n",
        "\n",
        "![image-2.png](attachment:image-2.png)\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "\n",
        "#### Leer e inspeccionar un DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yIdz9M3V5ufb"
      },
      "source": [
        "dat=pd.read_csv('CasosTotalesCumulativo.csv', delimiter=',')\n",
        "dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jc7DkG25ufc"
      },
      "source": [
        "dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0ROo4-T5ufc"
      },
      "source": [
        "dat.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifYSolSv5ufc"
      },
      "source": [
        "dat.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW5Ut16X5ufc"
      },
      "source": [
        "#### Índices y acceso a información de celdas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S1ivFFH5ufc"
      },
      "source": [
        "dat.iloc[1:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avGu4-Nx5ufc"
      },
      "source": [
        "dat['Region']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoGJ7dJs5ufc"
      },
      "source": [
        "dat_maule=dat[dat['Region']=='Maule']\n",
        "dat_maule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16V93wXM5ufd"
      },
      "source": [
        "#### Operaciones con columnas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozkqEkim5ufd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}